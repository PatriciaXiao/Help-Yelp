{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE processing y_train\n",
      "DONE processing y_val\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "X_train = pd.read_csv(\"./song_features/X_train.csv\")\n",
    "y_train = pd.read_csv(\"./song_features/y_train.csv\")\n",
    "X_val = pd.read_csv(\"./song_features/X_val.csv\")\n",
    "y_val = pd.read_csv(\"./song_features/y_val.csv\")\n",
    "X_test = pd.read_csv(\"./song_features/X_test.csv\")\n",
    "\n",
    "X_train = X_train.iloc[:,2:]\n",
    "X_val = X_val.iloc[:,2:]\n",
    "X_test = X_test.iloc[:,2:]\n",
    "\n",
    "# turn array\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "# turn y, since wanna treat this problem as a classification problem\n",
    "label_y_train=y_train.astype(np.int)\n",
    "label_y_val=y_val.astype(np.int)\n",
    "\n",
    "matrix_y_train = np.zeros((np.shape(y_train)[0],5))\n",
    "matrix_y_val = np.zeros((np.shape(y_val)[0],5))\n",
    "\n",
    "# print(np.shape(y_train)[0])\n",
    "\n",
    "for i in range(np.shape(y_train)[0]):\n",
    "    matrix_y_train[i][label_y_train[i]-1]=1\n",
    "print(\"DONE processing y_train\")\n",
    "    \n",
    "for i in range(np.shape(y_val)[0]):\n",
    "    matrix_y_val[i][label_y_val[i]-1]=1\n",
    "print(\"DONE processing y_val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150232, 57) (150232, 1) (50077, 57) (50077, 1) (50078, 57) (150232, 5) (50077, 5) (150232, 1) (50077, 1)\n"
     ]
    }
   ],
   "source": [
    "# get shape\n",
    "\n",
    "Xtrain_shape = np.shape(X_train)\n",
    "ytrain_shape = np.shape(y_train)\n",
    "Xval_shape = np.shape(X_val)\n",
    "yval_shape = np.shape(y_val)\n",
    "Xtest_shape = np.shape(X_test)\n",
    "matrixytrain_shape = np.shape(matrix_y_train)\n",
    "matrixyval_shape = np.shape(matrix_y_val)\n",
    "labelytrain_shape = np.shape(label_y_train)\n",
    "labelyval_shape = np.shape(label_y_val)\n",
    "print(Xtrain_shape,ytrain_shape,Xval_shape,yval_shape,Xtest_shape,matrixytrain_shape,matrixyval_shape,labelytrain_shape,labelyval_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sklearn for classification:\n",
    "# https://scikit-learn.org/stable/modules/multiclass.html\n",
    "# https://scikit-learn.org/stable/auto_examples/ensemble/plot_adaboost_multiclass.html\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # adaboost\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.ensemble import AdaBoostClassifier\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.datasets import make_gaussian_quantiles\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# bdt_real = AdaBoostClassifier(\n",
    "#     DecisionTreeClassifier(max_depth=2),\n",
    "#     n_estimators=50,\n",
    "#     learning_rate=1)\n",
    "\n",
    "# bdt_discrete = AdaBoostClassifier(\n",
    "#     DecisionTreeClassifier(max_depth=2),\n",
    "#     n_estimators=50,\n",
    "#     learning_rate=1.5,\n",
    "#     algorithm=\"SAMME\")\n",
    "\n",
    "# print(\"start bdt_real\")\n",
    "# bdt_real.fit(X_train, label_y_train)\n",
    "# print(\"start bdt_discrete\")\n",
    "# bdt_discrete.fit(X_train, label_y_train)\n",
    "\n",
    "# print(\"start predict real\")\n",
    "# y_pred_real = bdt_real.predict(X_train)\n",
    "\n",
    "# print(\"start predict discrete\")\n",
    "# y_pred_discrete = bdt_discrete.predict(X_train)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # show result\n",
    "# print('Training error of sklearn real AdaboostClassifier: %.2f' % (1-accuracy_score(label_y_train, y_pred_real)))\n",
    "# print('Training error of sklearn discrete AdaboostClassifier: %.2f' % (1-accuracy_score(label_y_train, y_pred_discrete)))\n",
    "\n",
    "# print(y_pred_discrete[0:50])\n",
    "# print(y_pred_real[0:50])\n",
    "# # print(label_y_train[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# binary classification\n",
    "# # Create and fit an AdaBoosted decision stump\n",
    "# bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=2),\n",
    "#                          algorithm=\"SAMME.R\",\n",
    "#                          n_estimators=50)\n",
    "# print(\"begin training\")\n",
    "# bdt.fit(X_train, matrix_y_train[:,2])\n",
    "# print(\"begin predicting\")\n",
    "# y_pred = bdt.predict(X_train)\n",
    "# print('Training error of sklearn AdaboostClassifier: %.2f' % (1-accuracy_score(matrix_y_train[:,2], y_pred)))\n",
    "# y_pred = bdt.predict(X_val)\n",
    "# print('Testing error of sklearn AdaboostClassifier: %.2f' % (1-accuracy_score(matrix_y_val[:,2], y_pred)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/EmilyW./anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/EmilyW./anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=57, activation=\"sigmoid\", units=10)`\n",
      "  \n",
      "/Users/EmilyW./anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=10, activation=\"softmax\", units=5)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# build model\n",
    "model = Sequential()\n",
    "# model.add(Dense(output_dim=128, input_dim=57, activation='relu'))\n",
    "# model.add(Dense(output_dim=64, input_dim=128, activation='relu'))\n",
    "# model.add(Dense(output_dim=32, input_dim=64, activation='relu'))\n",
    "# model.add(Dense(output_dim=32, input_dim=57, activation='sigmoid'))\n",
    "# model.add(Dense(output_dim=64, input_dim=57, activation='sigmoid'))\n",
    "model.add(Dense(output_dim=10, input_dim=57, activation='sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "# model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(output_dim=5, input_dim=10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # compile model\n",
    "sgd = optimizers.SGD(lr=0.005, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['accuracy'])\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(matrix_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "150232/150232 [==============================] - 3s 20us/step - loss: 0.1586 - acc: 0.3182: 0s - loss: 0.1591 - acc\n",
      "Epoch 2/50\n",
      "150232/150232 [==============================] - 2s 11us/step - loss: 0.1532 - acc: 0.3432\n",
      "Epoch 3/50\n",
      "150232/150232 [==============================] - 2s 12us/step - loss: 0.1517 - acc: 0.3414\n",
      "Epoch 4/50\n",
      "150232/150232 [==============================] - 2s 12us/step - loss: 0.1508 - acc: 0.3417\n",
      "Epoch 5/50\n",
      "150232/150232 [==============================] - 2s 12us/step - loss: 0.1503 - acc: 0.3426\n",
      "Epoch 6/50\n",
      "150232/150232 [==============================] - 3s 22us/step - loss: 0.1499 - acc: 0.3422: 1s -\n",
      "Epoch 7/50\n",
      "150232/150232 [==============================] - 2s 11us/step - loss: 0.1497 - acc: 0.3405\n",
      "Epoch 8/50\n",
      "150232/150232 [==============================] - 2s 12us/step - loss: 0.1494 - acc: 0.3426:\n",
      "Epoch 9/50\n",
      "150232/150232 [==============================] - 2s 11us/step - loss: 0.1492 - acc: 0.3431\n",
      "Epoch 10/50\n",
      "150232/150232 [==============================] - 2s 12us/step - loss: 0.1491 - acc: 0.3413\n",
      "Epoch 11/50\n",
      "150232/150232 [==============================] - 2s 11us/step - loss: 0.1488 - acc: 0.3442\n",
      "Epoch 12/50\n",
      "150232/150232 [==============================] - 2s 12us/step - loss: 0.1486 - acc: 0.3449\n",
      "Epoch 13/50\n",
      "150232/150232 [==============================] - 2s 11us/step - loss: 0.1486 - acc: 0.3428\n",
      "Epoch 14/50\n",
      "150232/150232 [==============================] - 2s 11us/step - loss: 0.1484 - acc: 0.3459\n",
      "Epoch 15/50\n",
      "150232/150232 [==============================] - 2s 12us/step - loss: 0.1483 - acc: 0.3466\n",
      "Epoch 16/50\n",
      "150232/150232 [==============================] - 2s 15us/step - loss: 0.1482 - acc: 0.3477\n",
      "Epoch 17/50\n",
      "150232/150232 [==============================] - 2s 15us/step - loss: 0.1481 - acc: 0.3456: 0s - loss: 0.1481 - acc: 0.34\n",
      "Epoch 18/50\n",
      "150232/150232 [==============================] - 3s 22us/step - loss: 0.1479 - acc: 0.3478\n",
      "Epoch 19/50\n",
      "150232/150232 [==============================] - 2s 13us/step - loss: 0.1479 - acc: 0.3473\n",
      "Epoch 20/50\n",
      "150232/150232 [==============================] - 2s 12us/step - loss: 0.1478 - acc: 0.3478\n",
      "Epoch 21/50\n",
      "150232/150232 [==============================] - 2s 12us/step - loss: 0.1477 - acc: 0.3463\n",
      "Epoch 22/50\n",
      "150232/150232 [==============================] - 2s 11us/step - loss: 0.1477 - acc: 0.3482\n",
      "Epoch 23/50\n",
      "150232/150232 [==============================] - 2s 11us/step - loss: 0.1475 - acc: 0.3479\n",
      "Epoch 24/50\n",
      "150232/150232 [==============================] - 2s 12us/step - loss: 0.1475 - acc: 0.3482\n",
      "Epoch 25/50\n",
      "150232/150232 [==============================] - 2s 12us/step - loss: 0.1475 - acc: 0.3475\n",
      "Epoch 26/50\n",
      "150232/150232 [==============================] - 2s 11us/step - loss: 0.1474 - acc: 0.3477\n",
      "Epoch 27/50\n",
      "150232/150232 [==============================] - 2s 12us/step - loss: 0.1474 - acc: 0.3484\n",
      "Epoch 28/50\n",
      "150232/150232 [==============================] - 2s 15us/step - loss: 0.1473 - acc: 0.3481\n",
      "Epoch 29/50\n",
      "150232/150232 [==============================] - 2s 11us/step - loss: 0.1473 - acc: 0.3490\n",
      "Epoch 30/50\n",
      "150232/150232 [==============================] - 2s 11us/step - loss: 0.1473 - acc: 0.3496\n",
      "Epoch 31/50\n",
      "150232/150232 [==============================] - 2s 12us/step - loss: 0.1472 - acc: 0.3484: 1s - loss: \n",
      "Epoch 32/50\n",
      "150232/150232 [==============================] - 2s 12us/step - loss: 0.1472 - acc: 0.3497\n",
      "Epoch 33/50\n",
      "150232/150232 [==============================] - 2s 11us/step - loss: 0.1472 - acc: 0.3492\n",
      "Epoch 34/50\n",
      "150232/150232 [==============================] - 2s 11us/step - loss: 0.1472 - acc: 0.3489\n",
      "Epoch 35/50\n",
      "150232/150232 [==============================] - 2s 12us/step - loss: 0.1471 - acc: 0.3490\n",
      "Epoch 36/50\n",
      "150232/150232 [==============================] - 3s 17us/step - loss: 0.1472 - acc: 0.3472\n",
      "Epoch 37/50\n",
      "150232/150232 [==============================] - 2s 13us/step - loss: 0.1471 - acc: 0.3485\n",
      "Epoch 38/50\n",
      "150232/150232 [==============================] - 2s 12us/step - loss: 0.1471 - acc: 0.3507\n",
      "Epoch 39/50\n",
      "150232/150232 [==============================] - 2s 14us/step - loss: 0.1470 - acc: 0.3521\n",
      "Epoch 40/50\n",
      "150232/150232 [==============================] - 2s 11us/step - loss: 0.1470 - acc: 0.3540\n",
      "Epoch 41/50\n",
      "150232/150232 [==============================] - 2s 11us/step - loss: 0.1470 - acc: 0.3541\n",
      "Epoch 42/50\n",
      "150232/150232 [==============================] - 2s 14us/step - loss: 0.1470 - acc: 0.3542\n",
      "Epoch 43/50\n",
      "150232/150232 [==============================] - 2s 12us/step - loss: 0.1470 - acc: 0.3547\n",
      "Epoch 44/50\n",
      "150232/150232 [==============================] - 2s 12us/step - loss: 0.1470 - acc: 0.3552\n",
      "Epoch 45/50\n",
      "150232/150232 [==============================] - 2s 11us/step - loss: 0.1470 - acc: 0.3561\n",
      "Epoch 46/50\n",
      "150232/150232 [==============================] - 2s 12us/step - loss: 0.1470 - acc: 0.3561\n",
      "Epoch 47/50\n",
      "150232/150232 [==============================] - 2s 12us/step - loss: 0.1469 - acc: 0.3565\n",
      "Epoch 48/50\n",
      "150232/150232 [==============================] - 2s 12us/step - loss: 0.1469 - acc: 0.3566\n",
      "Epoch 49/50\n",
      "150232/150232 [==============================] - 2s 12us/step - loss: 0.1469 - acc: 0.3565\n",
      "Epoch 50/50\n",
      "150232/150232 [==============================] - 2s 12us/step - loss: 0.1469 - acc: 0.3567\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x117ed8668>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# fit model\n",
    "model.fit(X_train, matrix_y_train, epochs=50, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_res = model.predict(X_train)\n",
    "y_resval = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "[[4. 5. 5. 4. 5. 5. 5. 4. 4. 4. 5. 2. 4. 5. 5. 3. 5. 5. 4. 3.]]\n",
      "[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "[[2. 5. 5. 5. 4. 5. 2. 5. 4. 4. 5. 3. 5. 1. 4. 5. 2. 5. 3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = y_res.argmax(axis=-1)+1\n",
    "y_predval = y_resval.argmax(axis=-1)+1\n",
    "# print(y_res[0:20])\n",
    "print(y_pred[0:20])\n",
    "print(np.transpose(y_train[0:20]))\n",
    "print(y_predval[0:20])\n",
    "print(np.transpose(y_val[0:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # keras prediction\n",
    "\n",
    "# # example of training a final regression model\n",
    "# from keras.models import Sequential\n",
    "# from keras import optimizers\n",
    "# from keras.layers import Dense, Dropout\n",
    "# from sklearn.datasets import make_regression\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# # # generate regression dataset\n",
    "# # X, y = make_regression(n_samples=100, n_features=2, noise=0.1, random_state=1)\n",
    "# # scalarX, scalarY = MinMaxScaler(), MinMaxScaler()\n",
    "# # scalarX.fit(X)\n",
    "# # scalarY.fit(y.reshape(100,1))\n",
    "# # X = scalarX.transform(X)\n",
    "# # y = scalarY.transform(y.reshape(100,1))\n",
    "# # define and fit the final model\n",
    "# model = Sequential()\n",
    "# model.add(Dense(25, input_dim=57, activation='linear'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(12, activation='linear'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(6, activation='linear'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(3, activation='linear'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(1, activation='linear'))\n",
    "# # model.compile(loss='mse', optimizer='sgd')\n",
    "# sgd = optimizers.SGD(lr=0.005, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "# model.fit(X_train, y_train, epochs=10)\n",
    "# # model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "# # model.fit(X_train, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y_res = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(y_res[0:10])\n",
    "# print(y_train[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # sklearn multiclass classification sample\n",
    "# print(__doc__)\n",
    "\n",
    "# # Author: Noel Dawe <noel.dawe@gmail.com>\n",
    "# #\n",
    "# # License: BSD 3 clause\n",
    "\n",
    "# from sklearn.externals.six.moves import zip\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# from sklearn.datasets import make_gaussian_quantiles\n",
    "# from sklearn.ensemble import AdaBoostClassifier\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "# X, y = make_gaussian_quantiles(n_samples=13000, n_features=10,\n",
    "#                                n_classes=3, random_state=1)\n",
    "\n",
    "# n_split = 3000\n",
    "\n",
    "# print(np.shape(y))\n",
    "\n",
    "# X_train, X_test = X[:n_split], X[n_split:]\n",
    "# y_train, y_test = y[:n_split], y[n_split:]\n",
    "\n",
    "# bdt_real = AdaBoostClassifier(\n",
    "#     DecisionTreeClassifier(max_depth=2),\n",
    "#     n_estimators=600,\n",
    "#     learning_rate=1)\n",
    "\n",
    "# bdt_discrete = AdaBoostClassifier(\n",
    "#     DecisionTreeClassifier(max_depth=2),\n",
    "#     n_estimators=600,\n",
    "#     learning_rate=1.5,\n",
    "#     algorithm=\"SAMME\")\n",
    "\n",
    "# bdt_real.fit(X_train, y_train)\n",
    "# bdt_discrete.fit(X_train, y_train)\n",
    "\n",
    "# real_test_errors = []\n",
    "# discrete_test_errors = []\n",
    "\n",
    "# for real_test_predict, discrete_train_predict in zip(\n",
    "#         bdt_real.staged_predict(X_test), bdt_discrete.staged_predict(X_test)):\n",
    "#     real_test_errors.append(\n",
    "#         1. - accuracy_score(real_test_predict, y_test))\n",
    "#     discrete_test_errors.append(\n",
    "#         1. - accuracy_score(discrete_train_predict, y_test))\n",
    "\n",
    "# n_trees_discrete = len(bdt_discrete)\n",
    "# n_trees_real = len(bdt_real)\n",
    "\n",
    "# # Boosting might terminate early, but the following arrays are always\n",
    "# # n_estimators long. We crop them to the actual number of trees here:\n",
    "# discrete_estimator_errors = bdt_discrete.estimator_errors_[:n_trees_discrete]\n",
    "# real_estimator_errors = bdt_real.estimator_errors_[:n_trees_real]\n",
    "# discrete_estimator_weights = bdt_discrete.estimator_weights_[:n_trees_discrete]\n",
    "\n",
    "# plt.figure(figsize=(15, 5))\n",
    "\n",
    "# plt.subplot(131)\n",
    "# plt.plot(range(1, n_trees_discrete + 1),\n",
    "#          discrete_test_errors, c='black', label='SAMME')\n",
    "# plt.plot(range(1, n_trees_real + 1),\n",
    "#          real_test_errors, c='black',\n",
    "#          linestyle='dashed', label='SAMME.R')\n",
    "# plt.legend()\n",
    "# plt.ylim(0.18, 0.62)\n",
    "# plt.ylabel('Test Error')\n",
    "# plt.xlabel('Number of Trees')\n",
    "\n",
    "# plt.subplot(132)\n",
    "# plt.plot(range(1, n_trees_discrete + 1), discrete_estimator_errors,\n",
    "#          \"b\", label='SAMME', alpha=.5)\n",
    "# plt.plot(range(1, n_trees_real + 1), real_estimator_errors,\n",
    "#          \"r\", label='SAMME.R', alpha=.5)\n",
    "# plt.legend()\n",
    "# plt.ylabel('Error')\n",
    "# plt.xlabel('Number of Trees')\n",
    "# plt.ylim((.2,\n",
    "#          max(real_estimator_errors.max(),\n",
    "#              discrete_estimator_errors.max()) * 1.2))\n",
    "# plt.xlim((-20, len(bdt_discrete) + 20))\n",
    "\n",
    "# plt.subplot(133)\n",
    "# plt.plot(range(1, n_trees_discrete + 1), discrete_estimator_weights,\n",
    "#          \"b\", label='SAMME')\n",
    "# plt.legend()\n",
    "# plt.ylabel('Weight')\n",
    "# plt.xlabel('Number of Trees')\n",
    "# plt.ylim((0, discrete_estimator_weights.max() * 1.2))\n",
    "# plt.xlim((-20, n_trees_discrete + 20))\n",
    "\n",
    "# # prevent overlapping y-axis labels\n",
    "# plt.subplots_adjust(wspace=0.25)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
